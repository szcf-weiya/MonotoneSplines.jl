var documenterSearchIndex = {"docs":
[{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"EditURL = \"https://github.com/szcf-weiya/MonotoneSplines.jl/blob/master/examples/monofit.jl\"","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"This section shows how to conduct monotone fitting with monotone splines with the existing optimization toolbox. The smoothing parameter can be tuned by cross-validation. We also compare the monotone splines with the popular smoothing splines (R's implementation smooth.spline).","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"using MonotoneSplines\nusing Plots\nusing Random\nusing RCall","category":"page"},{"location":"examples/monofit/#Cubic-Curve","page":"Monotone Fitting","title":"Cubic Curve","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"n = 100\nseed = 1234\nσ = 0.2\nRandom.seed!(seed)\nx = rand(n) * 2 .- 1\ny = x .^3 + randn(n) * σ\nλs = exp.(range(-10, -4, length = 100));\nnothing #hide","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Perform cross-validation for monotone fitting with smoothing splines,","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"@time errs, B, L, J = MonotoneSplines.cv_mono_ss(x, y, λs)","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Then plot the CV curve","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"scatter(log.(λs), errs, title = \"seed = $seed\")","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Then we can choose λ which minimized the CV error.","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"idx = argmin(errs)\nλopt = λs[idx]","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Fit with λopt","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"βhat, yhat = MonotoneSplines.mono_ss(B, y, L, J, λopt);\nnothing #hide","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Alternatively,","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"res = MonotoneSplines.mono_ss(x, y, λopt);\nyhat = res.fitted\nβhat = res.β","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"Plot it","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"scatter(x, y)\nscatter!(x, yhat)","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"We can also compare it with smooth.spline,","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"spl = R\"smooth.spline($x, $y)\"","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"it also determine λ by cross-validation,","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"λ = rcopy(R\"$spl$lambda\")","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"we can plot its fitting values together,","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"yhat_ss = rcopy(R\"predict($spl, $x)$y\")\nscatter!(x, yhat_ss)","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"For ease of demonstrating other examples, we wrap up the above procedures as a function","category":"page"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"function demo_mono_ss(x, y, λs)\n    errs, B, L, J = MonotoneSplines.cv_mono_ss(x, y, λs)\n    fig1 = plot(log.(λs), errs, xlab = \"λ\", ylab = \"CV error\", legend=false)\n    λopt = λs[argmin(errs)]\n    λ_mono_ss = [round(λopt, sigdigits = 4), round(log(λopt), sigdigits=4)]\n    yhat = MonotoneSplines.mono_ss(x, y, λopt).fitted\n    fig2 = scatter(x, y, label = \"obs.\")\n    scatter!(fig2, x, yhat, label = \"mono_ss (λ = $(λ_mono_ss[1]), logλ = $(λ_mono_ss[2]))\")\n    # ss\n    spl = R\"smooth.spline($x, $y)\"\n    λ = rcopy(R\"$spl$lambda\")\n    λ_ss = [round(λ, sigdigits = 4), round(log(λ), sigdigits=4)]\n    yhat_ss = rcopy(R\"predict($spl, $x)$y\")\n    scatter!(fig2, x, yhat_ss, label = \"ss (λ = $(λ_ss[1]), logλ = $(λ_ss[2]))\")\n    return plot(fig1, fig2, size = (1240, 420))\nend","category":"page"},{"location":"examples/monofit/#Growth-Curve","page":"Monotone Fitting","title":"Growth Curve","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"λs = exp.(range(-10, 0, length = 100));\nnothing #hide","category":"page"},{"location":"examples/monofit/#σ-3.0","page":"Monotone Fitting","title":"σ = 3.0","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"σ = 3.0\nRandom.seed!(seed)\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, z->1/(1-0.42log(z)), xmin = 0, xmax = 10)\nscatter(x, y)\nscatter!(x0, y0)\n\ndemo_mono_ss(x, y, λs)","category":"page"},{"location":"examples/monofit/#σ-2.0","page":"Monotone Fitting","title":"σ = 2.0","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"σ = 2.0\nRandom.seed!(seed)\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, z->1/(1-0.42log(z)), xmin = 0, xmax = 10)\nscatter(x, y)\nscatter!(x0, y0)\n\ndemo_mono_ss(x, y, λs)","category":"page"},{"location":"examples/monofit/#σ-0.5","page":"Monotone Fitting","title":"σ = 0.5","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"σ = 0.5\nRandom.seed!(seed)\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, z->1/(1-0.42log(z)), xmin = 0, xmax = 10)\nscatter(x, y)\nscatter!(x0, y0)\n\ndemo_mono_ss(x, y, λs)","category":"page"},{"location":"examples/monofit/#Logistic-Curve","page":"Monotone Fitting","title":"Logistic Curve","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"λs = exp.(range(-10, 0, length = 100));\nnothing #hide","category":"page"},{"location":"examples/monofit/#σ-0.2","page":"Monotone Fitting","title":"σ = 0.2","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"σ = 0.2\nRandom.seed!(seed)\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, z->exp(z)/(1+exp(z)), xmin = -5, xmax = 5)\nscatter(x, y)\nscatter!(x0, y0)\n\ndemo_mono_ss(x, y, λs)","category":"page"},{"location":"examples/monofit/#σ-1.0","page":"Monotone Fitting","title":"σ = 1.0","text":"","category":"section"},{"location":"examples/monofit/","page":"Monotone Fitting","title":"Monotone Fitting","text":"σ = 1.0\nRandom.seed!(seed)\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, z->exp(z)/(1+exp(z)), xmin = -5, xmax = 5)\nscatter(x, y)\nscatter!(x0, y0)\n\ndemo_mono_ss(x, y, λs)","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [MonotoneSplines]\nOrder = [:type, :function]","category":"page"},{"location":"api/#MonotoneSplines.Spl","page":"API","title":"MonotoneSplines.Spl","text":"A Spl object.\n\nFields\n\nH: an RObject generated by splines::bs()\nβ: the coefficients for the B-spline.\n\n\n\n\n\n","category":"type"},{"location":"api/#MonotoneSplines.aug-Tuple{AbstractFloat}","page":"API","title":"MonotoneSplines.aug","text":"aug(λ::AbstractFloat)\n\nAugment λ with 8 different functions.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.build_model-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.build_model","text":"build_model(x::AbstractVector{T}; <keyword arguments>)\n\nConstruct design matrix and other internal variables for smoothing spline.\n\nArguments\n\nall_knots = false: whether to use all knots. If false, use the same rule as in R's smooth.spline.\nprop_nknots = 1.0: a proportion for using fewer knots. Suppose the number of knots is nknots, then the final number of knots is prop_nknots * nknots. Currently, it is only effective when all_knots = false.\nε = 6.06e-6: a small number added to the diagonal of matrix Ω to ensure it is positive definite.\n\nReturns\n\nB-spline design matrix B at x for cubic splines\nL: cholesky decomposition of Ω = LL'\nJ: number of basis functions, which does not change for cubic splines, so it is only intended for smoothing splines \n\nthe above four are shared with the method for cubic splines, but for smoothing splines, it also returns \n\nmx, rx, idx, idx0: only for smoothing splines\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.build_model-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.build_model","text":"build_model(x::AbstractVector{T}, J::Int; <keyword arguments>)\n\nConstruct design matrix and other internal variables for cubic spline with J basis functions.\n\nReturns\n\nB: B-spline design matrix B at x for cubic splines\nrB: raw RObject of B\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.check_CI-Tuple{}","page":"API","title":"MonotoneSplines.check_CI","text":"check_CI(; <keyword arguments>)\n\nConduct repeated experiments to check the overlap of confidence bands (default, check_acc = false) or accuracy of fitting curves (check_acc = true) between MLP generator and OPT solution. \n\nArguments\n\nn = 100: sample size\nσ = 0.1: noise level\nf::Function = exp: the truth curve\nseed = 1234: random seed for the simulated data\ncheck_acc = false: check overlap of confidence bands (default: false) or accuracy of fitting curves (true)\nnepoch0 = 5: number of epoch in the first step to fit the curve\nnepoch = 50: number of epoch in the second step to obtain the confidence band\nniter_per_epoch = 100: number of iterations in each epoch\nη0 = 1e-4: learning rate in step 1\nη = 1e-4: learning rate in step 2 (NOTE: lr did not make much difference, unify these two)\nK0 = 32: Monte Carlo size for averaging λ in step 2\nK = 32: Monte Carlo size for averaging λ in step 1 and for averaging y in step 2. (NOTE: unify these two Monte Carlo size)\nnB = 2000: number of bootstrap replications\nnrep = 5: number of repeated experiments\nfig = true: whether to plot\nfigfolder = ~: folder for saving the figures if fig = true\nλs = exp.(range(-8, -2, length = 10)): region of continuous λ\nnhidden = 1000: number of hidden layers\ndepth = 2: depth of MLP\ndemo = false: whether to save internal results for demo purpose\nmodel_file = nothing: if not nothing, load the model from the file.\ngpu_id = 0: specify the id of GPU, -1 for CPU.\nprop_nknots = 0.2: proportion of number of knots in B-spline basis. \nbackend = \"flux\": train MLP generator with Flux or PyTorch\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.ci_mono_ss_mlp-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.ci_mono_ss_mlp","text":"ci_mono_ss_mlp(x::AbstractVector{T}, y::AbstractVector{T}, λs::AbstractVector{T}; )\n\nFit data x, y at each λs with confidence bands.\n\nArguments\n\nprop_nknots = 0.2: proportion of number of knots\nbackend = \"flux\": flux or pytorch\nmodel_file: path for saving trained model\nnepoch0 = 3: number of epoch in training step 1\nnepoch = 3: number of epoch in training step 2\nniter_per_epoch = 100: number of iterations in each epoch\nM = 10: Monte Carlo size\nnhidden = 100: number of hidden units\ndisable_progressbar = false: set true if generating documentation\ndevice = :cpu: train using :cpu or :gpu\nsort_in_nn = true: (only for backend = \"flux\") whether put sort in MLP \neval_in_batch = false: (only for backend = \"flux\") Currently, Flux does not support sort in batch mode. A workaround with customized Zygote.batch_sort needs further verifications. \n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.conf_band_width-Tuple{AbstractMatrix}","page":"API","title":"MonotoneSplines.conf_band_width","text":"conf_band_width(CIs::AbstractMatrix)\n\nCalculate width of confidence bands.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.coverage_prob-Tuple{AbstractMatrix, AbstractVector}","page":"API","title":"MonotoneSplines.coverage_prob","text":"coverage_prob(CIs::AbstractMatrix, y0::AbstractVector)\n\nCalculate coverage probability given n x 2 CI matrix CIs and true vector y0 of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.cv_mono_ss-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}, Tuple{AbstractVector{T}, AbstractVector{T}, Any}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.cv_mono_ss","text":"cv_mono_ss(x::AbstractVector{T}, y::AbstractVector{T}, λs::AbstractVector{T})\n\nCross-validation for monotone fitting with smoothing spline on y ~ x among parameters λs.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.div_into_folds-Tuple{Int64}","page":"API","title":"MonotoneSplines.div_into_folds","text":"div_into_folds(N::Int; K = 10, seed = 1234)\n\nEqually divide 1:N into K folds with random seed seed. If seed is negative, it is a non-random division, where the i-th fold would be the i-th equidistant range.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.eval_penalty-Union{Tuple{T}, Tuple{MonotoneSplines.Spl{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.eval_penalty","text":"eval_penalty(model::Spl{T}, x::AbstractVector{T})\n\nEvaluate the penalty matrix by R's fda::eval.penalty. To make sure the corresponding design matrix contructed by fda::eval.basis is the same as model.H, it asserts the norm difference should be smaller than sqrt(eps()).\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.fit","page":"API","title":"MonotoneSplines.fit","text":"fit(X, y, paras, method)\n\nparas is either the number of basis functions, or the sequence of interior knots. Return a Spl object.\n\nn = 100\nx = rand(n) * 2 .- 1\ny = x .^3 + randn(n) * 0.01\nres = fit(x, y, 10, \"monotone\")\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneSplines.gen_data-Tuple{Int64, Real, Function}","page":"API","title":"MonotoneSplines.gen_data","text":"gen_data(n, σ, f::Union{Function, String}; xmin = -1, xmax = 1, k = 10)\n\nGenerate n data points (xi, yi) from curve f with noise level σ, i.e., yi = f(xi) + N(0, σ^2).\n\nIt returns four vectors, x, y, x0, y0, where\n\nx, y: pair points of length n.\nx0, y0: true curve without noise, represented by k*n points.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.jaccard_index-Tuple{AbstractVector, AbstractVector}","page":"API","title":"MonotoneSplines.jaccard_index","text":"jaccard_index(a::AbstractVector, b::AbstractVector)\n\nCalculate Jaccard Index for two confidence intervals a and b\n\njaccard_index(a::AbstractMatrix, b::AbstractMatrix)\n\nCalculate Jaccard Index for two confidence intervals a[i, :] and b[i, :]\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.load_model-Tuple{Matrix, String}","page":"API","title":"MonotoneSplines.load_model","text":"load_model(n::Int, J::Int, nhidden::Int, model_file::String; dim_lam = 8, gpu_id = 3)\n\nLoad trained model from model_file.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.mono_cs","page":"API","title":"MonotoneSplines.mono_cs","text":"mono_cs(x::AbstractVector, y::AbstractVector, J::Int = 4; xnew = nothing)\n\nMonotone splines with cubic splines.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneSplines.mono_ss","page":"API","title":"MonotoneSplines.mono_ss","text":"mono_ss(x::AbstractVector, y::AbstractVector, λ = 1.0; prop_nknots = 1.0)\n\nMonotone splines with smoothing splines.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneSplines.mono_ss-2","page":"API","title":"MonotoneSplines.mono_ss","text":"mono_ss(B::AbstractMatrix, y::AbstractVector, L::AbstractMatrix, J::Int, λ::AbstractFloat)\n\nMonotone Fitting with Smoothing Splines given design matrix B and cholesky-decomposed matrix L.\n\nReturns\n\nβhat: estimated coefficient\nyhat: fitted values\n(optional) B and L\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneSplines.mono_ss_mlp-Tuple{AbstractVector, AbstractVector}","page":"API","title":"MonotoneSplines.mono_ss_mlp","text":"mono_ss_mlp(x::AbstractVector, y::AbstractVector; λl, λu)\n\nFit monotone smoothing spline by training a MLP generator.\n\nArguments\n\nprop_nknots = 0.2: proportion of number of knots\nbackend = flux: use flux or pytorch\ndevice = :cpu: use :cpu or :gpu\nnhidden = 100: number of hidden units\ndisable_progressbar = false: disable progressbar (useful in Documenter.jl)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.py_train_G_lambda-Tuple{AbstractVector, AbstractMatrix, AbstractMatrix}","page":"API","title":"MonotoneSplines.py_train_G_lambda","text":"py_train_G_lambda(y::AbstractVector, B::AbstractMatrix, L::AbstractMatrix; <keyword arguments>)\n\nWrapper for training MLP generator using PyTorch.\n\nArguments\n\nη0, η: learning rate\nK0, K: Monte Carlo size\nnepoch0, nepoch: number of epoch\nnhidden, depth: size of MLP\nλl, λu: range of λ\nuse_torchsort = false: torch.sort (default: false) or torchsort.soft_sort (true)\nsort_reg_strength = 0.1: tuning parameter when use_torchsort = true.\nmodel_file: path for saving trained model\ngpu_id = 0: use specified GPU\nniter_per_epoch = 100: number of iterations in each epoch\ndisable_tqdm = false: set true when generating documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.smooth_spline-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneSplines.smooth_spline","text":"smooth_spline(x::AbstractVector, y::AbstractVector, xnew::AbstractVector)\n\nPerform smoothing spline on (x, y), and make predictions on xnew.\n\nReturns: yhat, ynewhat,....\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.train_Gyλ-Tuple{AbstractVector, AbstractMatrix, AbstractMatrix, String}","page":"API","title":"MonotoneSplines.train_Gyλ","text":"train_Gyλ(rawy::AbstractVector, rawB::AbstractMatrix, rawL::AbstractMatrix, model_file::String)\n\nTrain MLP generator G(y, λ) for λ ∈ [λl, λu] and y ~ N(f, σ²)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneSplines.train_Gλ-Tuple{AbstractVector, AbstractMatrix, AbstractMatrix}","page":"API","title":"MonotoneSplines.train_Gλ","text":"train_Gλ(rawy::AbstractVector, rawB::AbstractMatrix, rawL::AbstractMatrix; λl, λu)\n\nTrain MLP generator G(λ) for λ ∈ [λl, λu].\n\n\n\n\n\n","category":"method"},{"location":"api/#RCall.rcopy-Tuple{MonotoneSplines.Spl}","page":"API","title":"RCall.rcopy","text":"rcopy(s::Spl)\n\nConvert RObject s.H as a Julia matrix, and s.β keeps the same.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Union{Tuple{T}, Tuple{MonotoneSplines.Spl{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"StatsAPI.predict","text":"predict(model::Spl{T}, xs::AbstractVector{T})\npredict(X::Vector{Float64}, y::Vector{Float64}, J::Int, Xnew::AbstractVector{Float64}, ynew::AbstractVector{Float64}\npredict(X::Vector{Float64}, y::Vector{Float64}, J::Int, Xnew::Vector{Float64}, ynew::Vector{Float64}, σ::Vector{Float64}\n\nMake prediction based on fitted Spl on new points xs. If Xnew is provided, then also returns the prediction error ‖yhat - ynew‖_2^2.\n\n\n\n\n\n","category":"method"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"EditURL = \"https://github.com/szcf-weiya/MonotoneSplines.jl/blob/master/examples/monoci_mlp.jl\"","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"This section illustrates how to obtain the confidence band with MLP generator. The confidence bands, either with PyTorch backend or Flux backend, are compared with the one calculated from classical parametric bootstrap.","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"using MonotoneSplines\nusing Plots","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Firstly, we generate data from y=exp(x)+N(0 01^2),","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"n = 20\nσ = 0.1\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, exp, seed = 1234);\nnothing #hide","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Consider lambda in lambda_l lambda_u,","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"λl = 1e-2\nλu = 1e-1\nλs = range(λl, λu, length = 2)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Run the optimization toolbox to fit the monotone spline, and conduct (parametric) bootstrap to obtain the confidence band of the fitted curve.","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"@time RES0 = [ci_mono_ss(x, y, λ, prop_nknots = 0.2) for λ in λs]\nYhat0 = hcat([RES0[i][1] for i=1:2]...)\nYCIs0 = [RES0[i][2] for i = 1:2]","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Estimate the confidence band with the Flux backend","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Yhat, YCIs, LOSS = ci_mono_ss_mlp(x, y, λs, prop_nknots = 0.2, device = :cpu, backend = \"flux\", nepoch0 = 1, nepoch = 1, disable_progressbar = true); #hide\n@time Yhat, YCIs, LOSS = ci_mono_ss_mlp(x, y, λs, prop_nknots = 0.2, device = :cpu, backend = \"flux\", nepoch0 = 5, nepoch = 5, disable_progressbar = true);\nnothing #hide","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Alternatively, we can also estimate it with the PyTorch backend","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"@time Yhat2, YCIs2, LOSS2 = ci_mono_ss_mlp(x, y, λs, prop_nknots = 0.2, device = :cpu, backend = \"pytorch\", nepoch0 = 5, nepoch = 5, disable_progressbar = true);\nnothing #hide","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"plot the traceplot of training loss","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"plot(log.(LOSS), label = \"MLP generator (Flux)\")\nplot!(log.(LOSS2), label = \"MLP generator (PyTorch)\")","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Calculate the jaccard index OPT solution vs MLP generator (Flux)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"[MonotoneSplines.jaccard_index(YCIs[i], YCIs0[i]) for i = 1:2]","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"OPT solution vs MLP generator (PyTorch)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"[MonotoneSplines.jaccard_index(YCIs2[i], YCIs0[i]) for i = 1:2]","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"note: Note\nFor simple demonstration, the training might not be sufficient, so the Jaccard index might not be good enough. For a better performance, please train it with a larger nepoch and nepoch0.","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"Plot the fitted curves and their confidence bands.","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"OPT solution vs MLP generator (Flux)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"scatter(x, y, label = \"\")\nplot!(x0, y0, label = \"truth\", legend = :topleft, ls = :dot)\nplot!(x, Yhat0[:, 1], label = \"OPT solution\")\nplot!(x, Yhat0[:, 2], label = \"OPT solution\")\nplot!(x, YCIs0[1][:, 1], fillrange = YCIs0[1][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, YCIs0[2][:, 1], fillrange = YCIs0[2][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, Yhat[:, 1], label = \"MLP generator (Flux)\", ls = :dash)\nplot!(x, Yhat[:, 2], label = \"MLP generator (Flux)\", ls = :dash)\nplot!(x, YCIs[1][:, 1], fillrange = YCIs[1][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, YCIs[2][:, 1], fillrange = YCIs[2][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"OPT solution vs MLP generator (PyTorch)","category":"page"},{"location":"examples/monoci_mlp/","page":"MLP Generator (confidence band)","title":"MLP Generator (confidence band)","text":"scatter(x, y, label = \"\")\nplot!(x0, y0, label = \"truth\", legend = :topleft, ls = :dot)\nplot!(x, Yhat0[:, 1], label = \"OPT solution\")\nplot!(x, Yhat0[:, 2], label = \"OPT solution\")\nplot!(x, YCIs0[1][:, 1], fillrange = YCIs0[1][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, YCIs0[2][:, 1], fillrange = YCIs0[2][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, Yhat2[:, 1], label = \"MLP generator (PyTorch)\", ls = :dash)\nplot!(x, Yhat2[:, 2], label = \"MLP generator (PyTorch)\", ls = :dash)\nplot!(x, YCIs2[1][:, 1], fillrange = YCIs2[1][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)\nplot!(x, YCIs2[2][:, 1], fillrange = YCIs2[2][:, 2], linealpha = 0, label = \"\", fillalpha = 0.5)","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"EditURL = \"https://github.com/szcf-weiya/MonotoneSplines.jl/blob/master/examples/diff_sort.jl\"","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"When using PyTorch backend in MLP generator, there are two choices for the sort operation:","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"the default torch.sort operation whose \"gradient\" is defined following the instruction for non-differentiable functions\na differentiable sort operation torchsort.soft_sort.","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"This section will compare these two operations and show that their difference are neglectable.","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"using MonotoneSplines\nusing Plots","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"First of all, generate data y = exp(x) + ϵ,","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"n = 20\nσ = 0.1\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, exp, seed = 1234);\nnothing #hide","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"Here we train a MLP network G(lambda = λ_0) to approximate the solution hatgamma_lambda_0 for a single lambda.","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"λl = 1e-2\nλu = λl\n@time Ghat1, loss1 = mono_ss_mlp(x, y, λl = λl, λu = λu, device = :cpu, prop_nknots = 0.2, backend = \"pytorch\",\n                                    use_torchsort=true, sort_reg_strength=1e-4, disable_progressbar = true);\n\n@time Ghat2, loss2 = mono_ss_mlp(x, y, λl = λl, λu = λu, device = :cpu, prop_nknots = 0.2, backend = \"pytorch\",\n                                    use_torchsort=true, sort_reg_strength=1e-1, disable_progressbar = true);\n\n@time Ghat3, loss3 = mono_ss_mlp(x, y, λl = λl, λu = λu, device = :cpu, prop_nknots = 0.2, backend = \"pytorch\",\n                                    use_torchsort=true, sort_reg_strength=1.0, disable_progressbar = true);\n\n@time Ghat4, loss4 = mono_ss_mlp(x, y, λl = λl, λu = λu, device = :cpu, prop_nknots = 0.2, backend = \"pytorch\",\n                                    use_torchsort=false, sort_reg_strength=1.0, disable_progressbar = true);\nnothing #hide","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"Evaluate the fitted curve,","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"λ = λl\nyhat1 = Ghat1(y, λ)\nyhat2 = Ghat2(y, λ)\nyhat3 = Ghat3(y, λ)\nyhat4 = Ghat4(y, λ);\nnothing #hide","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"The fitted curves are","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"scatter(x, y, label = \"\")\nplot!(x, yhat1, label = \"1e-4\")\nplot!(x, yhat2, label = \"1e-1\")\nplot!(x, yhat3, label = \"1\")\nplot!(x, yhat4, label = \"no\")","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"And the traing loss is","category":"page"},{"location":"examples/diff_sort/","page":"Differentiable Sort","title":"Differentiable Sort","text":"plot(loss1[1:100], label = \"1e-4\", xlab = \"iter\", ylab = \"loss\")\nplot!(loss2[1:100], label = \"1e-1\")\nplot!(loss3[1:100], label = \"1\")\nplot!(loss4[1:100], label = \"no\")","category":"page"},{"location":"#MonotoneSplines.jl-Documentation","page":"Home","title":"MonotoneSplines.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MonotoneSplines.jl is a Julia package for monotone splines, which impose a monotonicity constraint on the smoothing splines. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"undersetcolorredftextbf is monotonicargmin sum_i=1^nlefty_i-f(x_i)right^2 + lambda int leftf(t)right^2dt","category":"page"},{"location":"","page":"Home","title":"Home","text":"where f is formed with B-spline basis f(x) = sum_j=1^Jgamma_j B_j(x). A sufficient condition for f to be monotonic is gamma_1ldotsgamma_J is monotonic. With matrix notation mathbf y = y_1ldots y_n mathbf B_ij = B_j(x_i) boldsymbolOmega_ij = int B_i(s)B_j(s)ds, the problem can be rewritten as","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nundersetgammaargmin  Vert mathbf y - mathbf B gammaVert_2^2 + lambda gamma^TboldsymbolOmegagamma\ntextsubject to   alpha gamma_1 le alpha gamma_2le cdots le alphagamma_J\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where alpha=1 implies non-decreasing and alpha=-1 indicates non-increasing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package provides two algorithms (frameworks) for fitting the monotone splines.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Convert the problem into a classical convex second-order cone optimization problem. There are many mature existing optimization toolboxes can be used, such as ECOS.jl.\nApproximate the solution with an Multi-Layer Perceptrons (MLP) generator, using the powerful representation ability of neural network.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Particularly, the second approach can achieve good approximations and it can save much time by avoiding repeating to run the optimization problems of the first approach when we conduct bootstrap to estimate the confidence band. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"We do not reinvent the wheel. Instead, we fully take advantage of the existing widely-used implementations in other programming languages with the help of the flexible integration feature of Julia. For example, the package adopts the calculation of B-splines from R's splines package via RCall.jl, and provides the PyTorch deep learning backend via PyCall.jl as an alternative to the pure-Julia deep learning framework Flux.jl.","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"EditURL = \"https://github.com/szcf-weiya/MonotoneSplines.jl/blob/master/examples/monofit_mlp.jl\"","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"This section illustrates how to use the MLP generator to perform the monotone fitting. The MLP generator can achieve a perfect approximation to the fitting curve obtained from the optimization toolbox quickly. Particulaly, the MLP generator can save time by avoiding repeating to run the optimization toolbox for continuous lambda since it only needs to train once to obtain the function G(lambda), which can immediately return the solution at lambda=lambda_0 by simply evaluating G(lambda_0).","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"using MonotoneSplines\nusing Plots","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"We want to train a MLP generator G(λ) to approximate the solution for the monotone spline.","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"defbfymathbfy\ndefbBmathbfB\ndefbOmegaboldsymbolOmega\ndefsubtomathrmst\nbeginaligned\nmin_gamma  (bfy - bBgamma)^T(bfy - bBgamma) + lambdagamma^TbOmegagamma\nsubto  alphagamma_1 le cdots le alphagamma_J\nendaligned","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"First of all, generate data y = exp(x) + ϵ,","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"n = 20\nσ = 0.1\nx, y, x0, y0 = MonotoneSplines.gen_data(n, σ, exp, seed = 1234);\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/#single-λ","page":"MLP Generator (fitting curve)","title":"single λ","text":"","category":"section"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Here we train a MLP network G(lambda = λ_0) to approximate the solution.","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"λ = 1e-5;\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"By default, we use Flux.jl deep learning framework,","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Ghat, loss = mono_ss_mlp(x, y, λl = λ, λu = λ, device = :cpu, disable_progressbar = true); # hide\n@time Ghat, loss = mono_ss_mlp(x, y, λl = λ, λu = λ, device = :cpu, disable_progressbar = true);\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"we also support the well-known PyTorch backend with the help of PyCall.jl,","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"@time Ghat2, loss2 = mono_ss_mlp(x, y, λl = λ, λu = λ, device = :cpu, backend = \"pytorch\", disable_progressbar = true);\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"note: Note\nShowing the progressbar is quite useful in practice, but here in the documenter environment, it cannot display properly, so currently I simply disable it via disable_progressbar = true.","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"plot the log training loss","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"plot(log.(loss), label = \"Flux\")\nplot!(log.(loss2), label = \"Pytorch\")","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"The fitting can be obtained via evaluating at λ,","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"yhat = Ghat(y, λ);\nyhat2 = Ghat2(y, λ);\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"compare it with the optimization solution","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"yhat0 = mono_ss(x, y, λ, prop_nknots = 0.2).fitted;\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"plot the fitted curves","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"scatter(x, y, label = \"\")\nplot!(x0, y0, label = \"truth\", legend = :topleft, ls = :dot)\nplot!(x, yhat, label = \"MLP generator (Flux)\", ls = :dash, lw = 2)\nplot!(x, yhat0, label = \"OPT solution\")\nplot!(x, yhat2, label = \"MLP generator (Pytorch)\", ls = :dash, lw = 2)","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"The fitting curves obtained from optimization solution and MLP generator overlap quite well.","category":"page"},{"location":"examples/monofit_mlp/#continus-λ","page":"MLP Generator (fitting curve)","title":"continus λ","text":"","category":"section"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Here we train a generator G(lambda) lambdain lambda_l lambda_u,","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"λl = 1e-2\nλu = 1e-1\n@time Ghat, loss = mono_ss_mlp(x, y, λl = λl, λu = λu, prop_nknots = 0.2, device = :cpu);\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Plot the training losses along with the iterations.","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"plot(loss)","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Evaluate the generator at lambda_l, lambda_u and their middle lambda_m","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"λm = (λl + λu) / 2\nyhat_l = Ghat(y, λl)\nyhat_u = Ghat(y, λu)\nyhat_m = Ghat(y, λm)\nyhat0_l = mono_ss(x, y, λl, prop_nknots = 0.2).fitted;\nyhat0_u = mono_ss(x, y, λu, prop_nknots = 0.2).fitted;\nyhat0_m = mono_ss(x, y, λm, prop_nknots = 0.2).fitted;\nnothing #hide","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"Plot the fitting curves","category":"page"},{"location":"examples/monofit_mlp/","page":"MLP Generator (fitting curve)","title":"MLP Generator (fitting curve)","text":"scatter(x, y, label = \"\")\nplot!(x0, y0, label = \"truth\", legend = :topleft, ls = :dot)\nplot!(x, yhat0_l, label = \"OPT solution (λ = $λl)\")\nplot!(x, yhat_l, label = \"MLP generator (λ = $λl)\", ls = :dash, lw = 2)\nplot!(x, yhat0_m, label = \"OPT solution (λ = $λm)\")\nplot!(x, yhat_m, label = \"MLP generator (λ = $λm)\", ls = :dash, lw = 2)\nplot!(x, yhat0_u, label = \"OPT solution (λ = $λu)\")\nplot!(x, yhat_u, label = \"MLP generator (λ = $λu)\", ls = :dash, lw = 2)","category":"page"}]
}
